# 2024-2025å¹´äººå·¥æ™ºèƒ½é¢†åŸŸä¸»è¦è¿›å±• - å­¦ä¹ ç¬”è®°

## ğŸ“‹ å‰§é›†æ¦‚è§ˆ

| å­—æ®µ | ä¿¡æ¯ |
|------|------|
| **æ’­å®¢æ ‡é¢˜** | 2024-2025å¹´äººå·¥æ™ºèƒ½é¢†åŸŸä¸»è¦è¿›å±• |
| **å‰§é›†ç¼–å·** | 002 |
| **æ—¶é•¿** | 15-18åˆ†é’Ÿ |
| **éš¾åº¦** | é«˜çº§ (Advanced) |
| **ä¸»é¢˜** | AIé¢†åŸŸä¸»è¦æŠ€æœ¯è¿›å±• |
| **ä¸»æ’­** | Matthew |
| **æ—¥æœŸ** | 2026-02-11 |
| **æ¥æº** | Simon Willison, MIT Technology Review |

---

## ğŸ¯ å­¦ä¹ ç›®æ ‡

å®Œæˆæœ¬å‰§é›†å­¦ä¹ åï¼Œä½ å°†èƒ½å¤Ÿï¼š

- [ ] ç†è§£2024-2025å¹´AIé¢†åŸŸäº”å¤§è¶‹åŠ¿
- [ ] æŒæ¡20ä¸ªæ ¸å¿ƒAIæœ¯è¯­
- [ ] ç”¨è‹±è¯­è§£é‡Šæ¨ç†æ¨¡å‹ã€æ™ºèƒ½ä½“ç­‰æ¦‚å¿µ
- [ ] æè¿°ä¸­å›½AIæ¨¡å‹çš„å´›èµ·
- [ ] è®¨è®ºAIå¯è§£é‡Šæ€§ç ”ç©¶

---

## ğŸ“ å‰§é›†æ‘˜è¦

### ç®€è¦æ¦‚è¿° (3-5å¥è¯)

2024è‡³2025å¹´æ˜¯äººå·¥æ™ºèƒ½å‘å±•çš„å…³é”®è½¬æŠ˜æœŸã€‚æ¨ç†æ¨¡å‹çš„çªç ´ï¼ˆRLVRæŠ€æœ¯ï¼‰ä½¿LLMå…·å¤‡äº†çœŸæ­£æ„ä¹‰ä¸Šçš„é—®é¢˜è§£å†³èƒ½åŠ›ï¼›Anthropicçš„Claude Codeå¼•å‘ç¼–ç æ™ºèƒ½ä½“é©å‘½ï¼›ä¸­å›½AIä¼ä¸šå¼ºåŠ¿å´›èµ·ï¼Œåœ¨å¼€æºæƒé‡æ¨¡å‹é¢†åŸŸå®ç°å¯¹ç¾å›½é¡¶å°–ä¼ä¸šçš„è¿½èµ¶ç”šè‡³è¶…è¶Šï¼›å¤šæ¨¡æ€å›¾åƒç”Ÿæˆè¾¾åˆ°ä¸“ä¸šçº§æ°´å‡†ï¼›æœºæ¢°å¯è§£é‡Šæ€§ç ”ç©¶æ­ç¤ºäº†æ¨¡å‹å†…éƒ¨å·¥ä½œæ–¹å¼çš„æƒŠäººå‘ç°ã€‚

### æ ¸å¿ƒè¦ç‚¹

1. **æ¨ç†é©å‘½**ï¼šOpenAI o1å¼€å¯RLVRæ¨ç†æ¨¡å‹æ—¶ä»£ï¼Œ2025å¹´o3ã€Claude 4ã€Gemini 2.5ç›¸ç»§å‘å¸ƒ
2. **æ™ºèƒ½ä½“å…ƒå¹´**ï¼šClaude Codeè¾¾åˆ°10äº¿ç¾å…ƒå¹´æ”¶å…¥ï¼Œå¼‚æ­¥ç¼–ç æ™ºèƒ½ä½“æˆä¸ºä¸»æµ
3. **ä¸­å›½å´›èµ·**ï¼šDeepSeek R1å¼•å‘å¸‚åœºéœ‡åŠ¨ï¼Œå‰5åå¼€æºæ¨¡å‹å‡ä¸ºä¸­å›½äº§
4. **å¤šæ¨¡æ€çªç ´**ï¼šGPT-4oå›¾åƒç”Ÿæˆä¸€å‘¨1äº¿ç”¨æˆ·ï¼ŒNano Banana Proè¾¾ä¸“ä¸šçº§
5. **å¯è§£é‡Šæ€§**ï¼šç¨€ç–è‡ªç¼–ç å™¨æ­ç¤ºæ¨¡å‹å†…éƒ¨æœºåˆ¶ï¼Œå‘ç°"ç´§æ€¥å¯¹é½å¤±æ•ˆ"ç°è±¡

---

## ğŸ“– è¯æ±‡ç§¯ç´¯

### æ ¸å¿ƒè¯æ±‡ (20ä¸ª)

| # | è¯æ±‡ | éŸ³æ ‡ | è¯æ€§ | å®šä¹‰ | ä¸­æ–‡ | ä¾‹å¥ | é¢‘ç‡ |
|---|------|------|------|------|------|------|------|
| 1 | **Reasoning model** | /ËˆriËzÉ™nÉªÅ‹ ËˆmÉ’dl/ | n. | AI trained with RLVR for step-by-step problem solving | æ¨ç†æ¨¡å‹ | "OpenAI o1 was the first reasoning model." | â˜…â˜…â˜…â˜…â˜… |
| 2 | **RLVR** | /É‘Ër el viË É‘Ër/ | n. | Reinforcement Learning from Verifiable Rewards | å¼ºåŒ–å­¦ä¹ å¯éªŒè¯å¥–åŠ± | "RLVR enabled models to develop reasoning behaviors." | â˜…â˜…â˜…â˜…â˜… |
| 3 | **Chain of thought** | /tÊƒeÉªn É™v Î¸É”Ët/ | n. | Intermediate reasoning steps | æ€ç»´é“¾ | "Reasoning models write chain of thought to track progress." | â˜…â˜…â˜…â˜…â˜… |
| 4 | **Coding agent** | /ËˆkÉ™ÊŠdÉªÅ‹ ËˆeÉªdÊ’É™nt/ | n. | AI that writes and debugs code autonomously | ç¼–ç æ™ºèƒ½ä½“ | "Claude Code is the most prominent coding agent." | â˜…â˜…â˜…â˜…â˜… |
| 5 | **Asynchronous agent** | /eÉªËˆsÉªÅ‹krÉ™nÉ™s ËˆeÉªdÊ’É™nt/ | n. | Agents working without real-time supervision | å¼‚æ­¥æ™ºèƒ½ä½“ | "Claude Code for web is an asynchronous coding agent." | â˜…â˜…â˜…â˜…â˜† |
| 6 | **Tool-use** | /ËˆtuËl juËz/ | n. | LLM calling external functions | å·¥å…·ä½¿ç”¨ | "Tool-use enables complex multi-step tasks." | â˜…â˜…â˜…â˜…â˜† |
| 7 | **Open-weight model** | /ËˆÉ™ÊŠpÉ™n ËˆweÉªt ËˆmÉ’dl/ | n. | Models with publicly available parameters | å¼€æºæƒé‡æ¨¡å‹ | "Chinese open-weight models now rank among the world's best." | â˜…â˜…â˜…â˜…â˜… |
| 8 | **DeepSeek R1** | /diËp siËk É‘Ër ËˆwÊŒn/ | n. | Reasoning model from Chinese startup DeepSeek | DeepSeek R1 | "DeepSeek R1 triggered the 'DeepSeek moment' in markets." | â˜…â˜…â˜…â˜…â˜… |
| 9 | **Multimodal AI** | /ËŒmÊŒltÉªËˆmÉ™ÊŠdl eÉª aÉª/ | n. | AI processing multiple data types | å¤šæ¨¡æ€AI | "GPT-4o and Gemini are leading multimodal systems." | â˜…â˜…â˜…â˜…â˜… |
| 10 | **Ghiblification** | /É¡ÉªblÉªfÉªËˆkeÉªÊƒÉ™n/ | n. | Transforming images to Ghibli animation style | å‰åœåŠ›åŒ– | "Ghiblification became the viral AI trend of 2025." | â˜…â˜…â˜…â˜†â˜† |
| 11 | **Mechanistic interpretability** | /ËŒmekÉ™ËˆnÉªstÉªk ÉªnËŒtÉœËprÉªtÉ™ËˆbÉªlÉ™ti/ | n. | Understanding model internals | æœºæ¢°å¯è§£é‡Šæ€§ | "Mechanistic interpretability treats LLMs like alien biology." | â˜…â˜…â˜…â˜†â˜† |
| 12 | **Sparse autoencoder** | /spÉ‘Ës ËŒÉ”ËtÉ™ÊŠenkËˆÉ™ÊŠdÉ™/ | n. | Neural network making models more interpretable | ç¨€ç–è‡ªç¼–ç å™¨ | "Anthropic uses sparse autoencoders to study model internals." | â˜…â˜…â˜…â˜†â˜† |
| 13 | **Emergent misalignment** | /ÉªËˆmÉœËdÊ’É™nt ËŒmÉªsÉ™lËˆaÉªnmÉ™nt/ | n. | Unintended behavioral changes | ç´§æ€¥å¯¹é½å¤±æ•ˆ | "Emergent misalignment shows how bad training corrupts models." | â˜…â˜…â˜†â˜†â˜† |
| 14 | **Reinforcement Learning** | /riËÉªnËˆfÉ”ËsmÉ™nt ËˆlÉœËnÉªÅ‹/ | n. | Training using rewards | å¼ºåŒ–å­¦ä¹  | "Reinforcement Learning from Verifiable Rewards enabled reasoning." | â˜…â˜…â˜…â˜…â˜… |
| 15 | **AI agent** | /eÉª aÉª ËˆeÉªdÊ’É™nt/ | n. | LLM systems that use tools to achieve goals | AIæ™ºèƒ½ä½“ | "AI agents represent a fundamental shift in human-AI collaboration." | â˜…â˜…â˜…â˜…â˜… |
| 16 | **Claude Code** | /klÉ”Ëd kÉ™ÊŠd/ | n. | Anthropic's coding agent tool | Claude Code | "Claude Code reached $1 billion in annual revenue." | â˜…â˜…â˜…â˜…â˜… |
| 17 | **Nano Banana** | /ËˆnÃ¦nÉ™ÊŠ bÉ™ËˆnÃ¦nÉ™/ | n. | Google's image generation model | Nano Banana | "Nano Banana Pro can generate professional infographics." | â˜…â˜…â˜…â˜†â˜† |
| 18 | **GPT-5** | /dÊ’iË piË tiË faÉªv/ | n. | OpenAI's flagship model (2025) | GPT-5 | "GPT-5 Thinking can accomplish tasks taking humans multiple hours." | â˜…â˜…â˜…â˜…â˜… |
| 19 | **Gemini** | /dÊ’É™ËˆmaÉªni/ | n. | Google's AI model series | Gemini | "Gemini 3.0 was released in November 2025." | â˜…â˜…â˜…â˜…â˜… |
| 20 | **Claude 4** | /klÉ”Ëd fÉ”Ë/ | n. | Anthropic's 2025 model series | Claude 4 | "Claude 4 Opus 4.5 has strong reasoning and coding abilities." | â˜…â˜…â˜…â˜…â˜… |

### å­¦æœ¯å’Œä¸“ä¸šè¡¨è¾¾

| è¡¨è¾¾ | å«ä¹‰ | ä¸­æ–‡ | è¯­å¢ƒ/ç”¨æ³• | ä¾‹å¥ |
|------|------|------|----------|------|
| **Reasoning revolution** | æ¨ç†èƒ½åŠ›çªç ´å¸¦æ¥çš„å˜é© | æ¨ç†é©å‘½ | æŠ€æœ¯è¶‹åŠ¿è®¨è®º | "The reasoning revolution changed how we think about AI capabilities." |
| **Year of agents** | æ™ºèƒ½ä½“æŠ€æœ¯æˆç†Ÿçš„å¹´ä»½ | æ™ºèƒ½ä½“ä¹‹å¹´ | å¹´åº¦æ€»ç»“ | "2025 was widely called the 'year of agents'." |
| **DeepSeek moment** | DeepSeekå¼•å‘çš„å¸‚åœºéœ‡åŠ¨äº‹ä»¶ | DeepSeekæ—¶åˆ» | å¸‚åœºåˆ†æ | "The DeepSeek moment triggered a $593 billion selloff in Nvidia." |
| **Ghiblification** | å›¾åƒå‰åœåŠ›åŒ–é£æ ¼è½¬æ¢ | å‰åœåŠ›åŒ– | ç¤¾äº¤åª’ä½“è¶‹åŠ¿ | "Ghiblification went viral on social media." |
| **Model internals** | æ¨¡å‹å†…éƒ¨å·¥ä½œæœºåˆ¶ | æ¨¡å‹å†…éƒ¨ | å¯è§£é‡Šæ€§ç ”ç©¶ | "Scientists study model internals to understand AI behavior." |
| **Tool calling** | æ¨¡å‹è°ƒç”¨å¤–éƒ¨å·¥å…·çš„èƒ½åŠ› | å·¥å…·è°ƒç”¨ | æ™ºèƒ½ä½“åŠŸèƒ½ | "Tool calling enables LLMs to interact with external systems." |

---

## âœï¸ è¯­æ³•ä¸å¥å‹

### å…³é”®å¥å‹

1. **X triggered Y**
   - **ç»“æ„**: Xå¼•å‘äº†Yï¼ˆé€šå¸¸æŒ‡é‡å¤§äº‹ä»¶ï¼‰
   - **ä¸­æ–‡**: Xå¼•å‘äº†Y
   - **ä¾‹å¥**: "DeepSeek R1 triggered a major market reaction, with Nvidia losing $593 billion in market cap."
   - **ä½ çš„ç»ƒä¹ **: _____________________________________

2. **X reached $Y in revenue**
   - **ç»“æ„**: Xè¾¾åˆ°äº†Yç¾å…ƒçš„å¹´æ”¶å…¥
   - **ä¸­æ–‡**: Xè¾¾åˆ°Yç¾å…ƒå¹´æ”¶å…¥
   - **ä¾‹å¥**: "By December, Anthropic reported Claude Code reached $1 billion in annual revenue."
   - **ä½ çš„ç»ƒä¹ **: _____________________________________

3. **X represents a fundamental shift in Y**
   - **ç»“æ„**: Xä»£è¡¨äº†Yé¢†åŸŸçš„æ ¹æœ¬æ€§è½¬å˜
   - **ä¸­æ–‡**: Xä»£è¡¨äº†Yé¢†åŸŸçš„æ ¹æœ¬æ€§è½¬å˜
   - **ä¾‹å¥**: "Coding agents represent a fundamental shift in how we work with AI."
   - **ä½ çš„ç»ƒä¹ **: _____________________________________

4. **X became Y's gold standard**
   - **ç»“æ„**: Xæˆä¸ºYé¢†åŸŸçš„é»„é‡‘æ ‡å‡†
   - **ä¸­æ–‡**: Xæˆä¸ºYé¢†åŸŸçš„é»„é‡‘æ ‡å‡†
   - **ä¾‹å¥**: "Google's Nano Banana became the image generation gold standard."
   - **ä½ çš„ç»ƒä¹ **: _____________________________________

### è¿‡æ¸¡è¯ä¸çŸ­è¯­

| ç±»åˆ« | è¯æ±‡/çŸ­è¯­ | ä¸­æ–‡ | ç”¨æ³• | ä¾‹å¥ |
|------|----------|------|------|------|
| æ·»åŠ ä¿¡æ¯ | **Furthermore** | æ­¤å¤– | æ·»åŠ ç±»ä¼¼è§‚ç‚¹ | "GPT-4o was impressive. Furthermore, the new image features drove massive adoption." |
| æ·»åŠ ä¿¡æ¯ | **In addition** | å¦å¤– | æ·»åŠ æ”¯æŒç‚¹ | "Reasoning models improved. In addition, agent tools became more reliable." |
| å¯¹æ¯” | **However** | ç„¶è€Œ | æ˜¾ç¤ºå·®å¼‚ | "Chinese models were behind. However, by 2025 they led the open-weight rankings." |
| å› æœ | **As a result** | ç»“æœæ˜¯ | æ˜¾ç¤ºç»“æœ | "Reasoning models improved capabilities. As a result, new applications emerged." |
| ä¸¾ä¾‹ | **For example** | ä¾‹å¦‚ | å¼•å…¥ä¾‹å­ | "AI made progress in many areas. For example, coding agents reached $1B revenue." |
| æ€»ç»“ | **In summary** | æ€»ä¹‹ | æ€»ç»“è§‚ç‚¹ | "In summary, 2025 was transformative for AI development." |

---

## ğŸ“ ç†è§£æ£€æŸ¥

### å¿«é€Ÿå›é¡¾é—®é¢˜

1. **What technology enabled the "reasoning revolution"?**
   - **ç­”æ¡ˆ**: Reinforcement Learning from Verifiable Rewards (RLVR)
   - **ä¸­æ–‡**: å¼ºåŒ–å­¦ä¹ å¯éªŒè¯å¥–åŠ±

2. **How much revenue did Claude Code reach by December 2025?**
   - **ç­”æ¡ˆ**: $1 billion in annual revenue
   - **ä¸­æ–‡**: 10äº¿ç¾å…ƒå¹´æ”¶å…¥

3. **Which country's models ranked in the top 5 open-weight models?**
   - **ç­”æ¡ˆ**: China
   - **ä¸­æ–‡**: ä¸­å›½

4. **What viral trend emerged from AI image generation in 2025?**
   - **ç­”æ¡ˆ**: Ghiblification
   - **ä¸­æ–‡**: å‰åœåŠ›åŒ–

5. **What did Anthropic use to study model internals?**
   - **ç­”æ¡ˆ**: Sparse autoencoders
   - **ä¸­æ–‡**: ç¨€ç–è‡ªç¼–ç å™¨

### è®¨è®ºè¯é¢˜

1. **æ¨ç†æ¨¡å‹çš„å•†ä¸šåº”ç”¨**
   - "How might reasoning models change professional work in fields like law, medicine, or finance?"
   - *ä¸­æ–‡*: æ¨ç†æ¨¡å‹å¦‚ä½•æ”¹å˜æ³•å¾‹ã€åŒ»å­¦æˆ–é‡‘èç­‰é¢†åŸŸçš„ä¸“ä¸šå·¥ä½œï¼Ÿ
   - *æŒ‡å¯¼*: Consider the implications of AI that can work for hours on complex problems.

2. **ä¸­å›½AIçš„å…¨çƒå½±å“**
   - "What does the rise of Chinese AI models mean for the global technology landscape?"
   - *ä¸­æ–‡*: ä¸­å›½AIçš„å´›èµ·å¯¹å…¨çƒæŠ€æœ¯æ ¼å±€æ„å‘³ç€ä»€ä¹ˆï¼Ÿ
   - *æŒ‡å¯¼*: Consider competition, innovation, and geopolitical implications.

3. **AIå®‰å…¨ä¸å¯è§£é‡Šæ€§**
   - "Why is understanding model internals important for AI safety?"
   - *ä¸­æ–‡*: ç†è§£æ¨¡å‹å†…éƒ¨å¯¹AIå®‰å…¨ä¸ºä½•é‡è¦ï¼Ÿ
   - *æŒ‡å¯¼*: Connect to the "emergent misalignment" and "lethal trifecta" concepts.

---

## ğŸ“š å‚è€ƒæ¥æº

1. Willison S. (2025). 2025: The year in LLMs. Simon Willison's Weblog. https://simonwillison.net/2025/Dec/31/the-year-in-llms/

2. MIT Technology Review. (2026). Meet the new biologists treating LLMs like aliens. https://www.technologyreview.com/2026/01/12/1129782/ai-large-language-models-biology-alien-autopsy/

3. Vellum. (2025). Flagship Model Report: GPT-5.1 vs Gemini 3 Pro vs Claude Opus 4.5. https://www.vellum.ai/blog/flagship-model-report

4. Digital Bricks. (2025). AI Progress in 2025: What's Happened and What's Next. https://www.digitalbricks.ai/blog-posts/ai-progress-in-2025-whats-happened-and-whats-next

---

## ğŸ“… å­¦ä¹ è®¡åˆ’

| å¤©æ•° | æ´»åŠ¨ | æ—¶é—´ | å®Œæˆ |
|------|------|------|------|
| ç¬¬1å¤© | å¬æ’­å®¢+è®°ç¬”è®° | 20åˆ†é’Ÿ | [ ] |
| ç¬¬2å¤© | å¤ä¹ è¯æ±‡(1-10) | 15åˆ†é’Ÿ | [ ] |
| ç¬¬3å¤© |11-20) | 15åˆ†é’Ÿ å¤ä¹ è¯æ±‡( | [ ] |
| ç¬¬4å¤© | è¯­æ³•ç»ƒä¹  | 20åˆ†é’Ÿ | [ ] |
| ç¬¬5å¤© | å£è¯­ç»ƒä¹  | 15åˆ†é’Ÿ | [ ] |
| ç¬¬6å¤© | å†™ä½œç»ƒä¹  | 20åˆ†é’Ÿ | [ ] |
| ç¬¬7å¤© | è‡ªæˆ‘è¯„ä¼° | 15åˆ†é’Ÿ | [ ] |

---

*å­¦ä¹ ç¬”è®°ç”Ÿæˆæ—¶é—´: 2026-02-11*
*ä½¿ç”¨English Learning Podcast Generator Skill v2.0*
*åŒ…å«ä¸­æ–‡ç¿»è¯‘å’Œè¯æ±‡ä¸­æ–‡æ„æ€*
