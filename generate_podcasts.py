#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Generate podcasts for both research topics using the new Skill
"""

import sys
sys.path.insert(0, '/root/.openclaw/skills/english-learning-podcast-generator')

from src import ContentAnalyzer, ScriptGenerator, LearningNotesGenerator, PodcastConfig

def generate_podcast(content: str, topic: str, style: str = "interview", level: str = "advanced"):
    """Generate complete podcast for given content"""
    print(f"\n{'='*60}")
    print(f"Generating podcast for: {topic}")
    print(f"{'='*60}")
    
    # é…ç½®
    config = PodcastConfig()
    config.script.style = style
    config.script.level = level
    
    # Stage 1: å†…å®¹åˆ†æ
    print(f"\nğŸ“Š Stage 1: Analyzing content...")
    analyzer = ContentAnalyzer(config)
    analysis = analyzer.analyze(content[:15000])  # Limit to 15k chars
    print(f"  âœ… Topic: {analysis.topic}")
    print(f"  âœ… Key points: {len(analysis.key_points)}")
    print(f"  âœ… Vocabulary: {len(analysis.vocabulary)} terms")
    print(f"  âœ… Difficulty: {analysis.difficulty_level}")
    
    # Stage 2: è„šæœ¬ç”Ÿæˆ
    print(f"\nğŸ“ Stage 2: Generating script...")
    script_gen = ScriptGenerator(config)
    script = script_gen.generate(analysis)
    print(f"  âœ… Words: {script.estimated_word_count}")
    print(f"  âœ… Duration: {script.estimated_duration_minutes} minutes")
    print(f"  âœ… Sections: {len(script.sections)}")
    
    # Stage 3: å­¦ä¹ ç¬”è®°
    print(f"\nğŸ“š Stage 3: Creating learning notes...")
    notes_gen = LearningNotesGenerator(config)
    notes = notes_gen.generate(script, analysis)
    print(f"  âœ… Vocabulary: {len(notes.vocabulary)} terms")
    print(f"  âœ… Phrases: {len(notes.phrases)}")
    print(f"  âœ… Comprehension questions: {len(notes.comprehension['questions'])}")
    
    return {
        'analysis': analysis,
        'script': script,
        'notes': notes
    }

# ä¸»ç¨‹åº
if __name__ == "__main__":
    import os
    
    # 1. æµè¡Œç—…å­¦ç ”ç©¶æŠ¥å‘Š
    print("\n" + "="*60)
    print("ğŸ™ï¸ GENERATING EPIDEMIOLOGY PODCAST")
    print("="*60)
    
    epi_file = '/root/clawd/knowledge_base/Epidemiology_Research/Epidemiology_Paradigms_Report.md'
    if os.path.exists(epi_file):
        with open(epi_file, 'r', encoding='utf-8') as f:
            epi_content = f.read()
        
        epi_result = generate_podcast(
            content=epi_content,
            topic="æµè¡Œç—…å­¦ç ”ç©¶èŒƒå¼",
            style="interview",
            level="advanced"
        )
        
        # ä¿å­˜è„šæœ¬
        with open('/root/clawd/knowledge_base/English_Podcasts/epidemiology_script_v3.md', 'w', encoding='utf-8') as f:
            f.write(f"# æµè¡Œç—…å­¦ç ”ç©¶èŒƒå¼ - è‹±è¯­å­¦ä¹ æ’­å®¢ v3.0\n\n")
            f.write(f"## å‰§é›†ä¿¡æ¯\n- **æ—¶é•¿**: {epi_result['script'].estimated_duration_minutes}åˆ†é’Ÿ\n")
            f.write(f"- **éš¾åº¦**: é«˜çº§\n- **é£æ ¼**: è®¿è°ˆå½¢å¼\n- **è¯æ±‡**: {len(epi_result['notes'].vocabulary)}ä¸ªæœ¯è¯­\n\n")
            f.write(f"## æ‘˜è¦\n{epi_result['analysis'].thesis}\n\n")
            f.write(f"## å…³é”®è¦ç‚¹ ({len(epi_result['analysis'].key_points)})\n")
            for i, point in enumerate(epi_result['analysis'].key_points, 1):
                f.write(f"{i}. {point[:100]}...\n")
            f.write("\n## è¯æ±‡è¡¨\n")
            for vocab in epi_result['notes'].vocabulary[:10]:
                f.write(f"- **{vocab['word']}**: {vocab.get('chinese', 'N/A')}\n")
        
        print(f"\nâœ… Saved: epidemiology_script_v3.md")
    else:
        print(f"âŒ File not found: {epi_file}")
    
    # 2. AIç ”ç©¶æŠ¥å‘Š
    print("\n" + "="*60)
    print("ğŸ™ï¸ GENERATING AI PODCAST")
    print("="*60)
    
    ai_file = '/root/clawd/knowledge_base/English_Podcasts/2024_2025_AI_Developments_Research_Report.md'
    if os.path.exists(ai_file):
        with open(ai_file, 'r', encoding='utf-8') as f:
            ai_content = f.read()
        
        ai_result = generate_podcast(
            content=ai_content,
            topic="AIé¢†åŸŸä¸»è¦è¿›å±•",
            style="interview", 
            level="advanced"
        )
        
        # ä¿å­˜è„šæœ¬
        with open('/root/clawd/knowledge_base/English_Podcasts/ai_script_v3.md', 'w', encoding='utf-8') as f:
            f.write(f"# 2024-2025å¹´AIé¢†åŸŸä¸»è¦è¿›å±• - è‹±è¯­å­¦ä¹ æ’­å®¢ v3.0\n\n")
            f.write(f"## å‰§é›†ä¿¡æ¯\n- **æ—¶é•¿**: {ai_result['script'].estimated_duration_minutes}åˆ†é’Ÿ\n")
            f.write(f"- **éš¾åº¦**: é«˜çº§\n- **é£æ ¼**: è®¿è°ˆå½¢å¼\n- **è¯æ±‡**: {len(ai_result['notes'].vocabulary)}ä¸ªæœ¯è¯­\n\n")
            f.write(f"## æ‘˜è¦\n{ai_result['analysis'].thesis}\n\n")
            f.write(f"## å…³é”®è¦ç‚¹ ({len(ai_result['analysis'].key_points)})\n")
            for i, point in enumerate(ai_result['analysis'].key_points, 1):
                f.write(f"{i}. {point[:100]}...\n")
            f.write("\n## è¯æ±‡è¡¨\n")
            for vocab in ai_result['notes'].vocabulary[:10]:
                f.write(f"- **{vocab['word']}**: {vocab.get('chinese', 'N/A')}\n")
        
        print(f"\nâœ… Saved: ai_script_v3.md")
    else:
        print(f"âŒ File not found: {ai_file}")
    
    print("\n" + "="*60)
    print("ğŸ‰ BOTH PODCASTS GENERATED SUCCESSFULLY!")
    print("="*60)

