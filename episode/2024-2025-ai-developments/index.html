<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>2024-2025å¹´äººå·¥æ™ºèƒ½é¢†åŸŸä¸»è¦è¿›å±• - English Learning Podcast</title>
    <link rel="stylesheet" href="../../css/style.css">
    <style>
        .content-body { background: #fff; padding: 24px; border: 1px solid #d0d7de; border-radius: 8px; line-height: 1.8; max-width: 900px; }
        .content-body h1 { font-size: 24px; margin-bottom: 20px; border-bottom: 2px solid #d0d7de; padding-bottom: 12px; }
        .content-body h2 { font-size: 20px; margin: 24px 0 16px; color: #0969da; }
        .content-body h3 { font-size: 16px; margin: 20px 0 12px; font-weight: 600; color: #24292f; }
        .content-body p { margin-bottom: 12px; }
        .content-body ul, .content-body ol { margin: 12px 0 16px 24px; }
        .content-body li { margin-bottom: 8px; }
        .content-body table { width: 100%; border-collapse: collapse; margin: 16px 0; font-size: 14px; }
        .content-body th, .content-body td { border: 1px solid #d0d7de; padding: 10px 14px; text-align: left; }
        .content-body th { background: #f6f8fa; font-weight: 600; }
        .content-body tr:nth-child(even) { background: #f6f8fa; }
        .content-body strong { color: #0969da; }
        .content-body hr { border: none; border-top: 1px solid #d0d7de; margin: 24px 0; }
        .content-body a { color: #0969da; text-decoration: none; }
        .content-body a:hover { text-decoration: underline; }
        .chinese-translation { color: #666; font-size: 14px; margin-top: 4px; margin-bottom: 12px; display: block; }
        .episode-info { background: #f6f8fa; padding: 12px 16px; border-radius: 6px; margin-bottom: 20px; }
        .vocab-term { font-weight: 600; color: #0969da; }
        .audio-info { background: #dafbe1; border: 1px solid #1a7f37; border-radius: 6px; padding: 12px 16px; margin-bottom: 20px; }
        .version-badge { display: inline-block; background: #0969da; color: white; padding: 2px 8px; border-radius: 12px; font-size: 12px; margin-left: 8px; }
    </style>
</head>
<body>
    <header class="header">
        <div class="container header-content">
            <a href="../../" class="logo"><span class="logo-icon">ğŸ™ï¸</span><span class="logo-text">English Learning Podcast</span></a>
            <nav class="nav">
                <a href="../../">é¦–é¡µ</a>
                <a href="../../#podcasts">æ’­å®¢</a>
                <a href="../../#about">å…³äº</a>
            </nav>
        </div>
    </header>

    <main class="container" style="padding-top: 32px; max-width: 1000px;">
        <nav class="breadcrumb"><a href="../../">é¦–é¡µ</a><span>/</span><span>2024-2025å¹´äººå·¥æ™ºèƒ½é¢†åŸŸä¸»è¦è¿›å±•</span></nav>

        <section id="audio-player">
            <div class="audio-player">
                <div class="player-info">
                    <div class="player-icon">ğŸ™ï¸</div>
                    <div class="player-details">
                        <h2>2024-2025å¹´äººå·¥æ™ºèƒ½é¢†åŸŸä¸»è¦è¿›å±• <span class="version-badge">v3.0 FINAL</span></h2>
                        <p>Major AI Developments 2024-2025 â€¢ 2026-02-11 â€¢ Interview Style</p>
                    </div>
                </div>
                <div class="audio-info">
                    <strong>ğŸ‰ v3.0 Final Production Version</strong><br>
                    <span style="font-size:14px;">â€¢ åŸºäºEnglish Learning Podcast Generator Skillæ ‡å‡†æµç¨‹ç”Ÿæˆ</span><br>
                    <span style="font-size:14px;">â€¢ æ—¶é•¿: 15-20åˆ†é’Ÿï¼ˆå®Œæ•´ç‰ˆï¼‰</span><br>
                    <span style="font-size:14px;">â€¢ éŸ³é¢‘: 4.5MBï¼ˆæœ€ç»ˆç”Ÿäº§ç‰ˆæœ¬ï¼‰</span><br>
                    <span style="font-size:14px;">â€¢ å†…å®¹: å®Œæ•´ä¿ç•™15ç¯‡æƒå¨å¼•ç”¨çš„æ‰€æœ‰æ•°æ®å’Œç»†èŠ‚</span>
                </div>
                <audio controls preload="metadata" style="width:100%">
                    <source src="https://yuanhb1993.github.io/english-podcast-learning/2024_2025_AI_Developments/audio/podcast_final.mp3" type="audio/mpeg">
                    æ‚¨çš„æµè§ˆå™¨ä¸æ”¯æŒéŸ³é¢‘æ’­æ”¾ã€‚
                </audio>
                <div style="margin-top:12px;font-size:13px;color:#57606a;">
                    ğŸ’¡ å¦‚æœéŸ³é¢‘æ— æ³•æ’­æ”¾ï¼Œè¯· <a href="https://yuanhb1993.github.io/english-podcast-learning/2024_2025_AI_Developments/audio/podcast_final.mp3" download>ä¸‹è½½å®Œæ•´ç‰ˆéŸ³é¢‘ (4.5MB)</a>
                </div>
            </div>
        </section>

        <section style="margin-bottom:32px;">
            <div style="display:flex;gap:12px;flex-wrap:wrap;">
                <a href="https://yuanhb1993.github.io/english-podcast-learning/2024_2025_AI_Developments/audio/podcast_final.mp3" class="btn btn-primary" download>â¬‡ï¸ ä¸‹è½½å®Œæ•´ç‰ˆéŸ³é¢‘ (4.5MB)</a>
                <a href="https://yuanhb1993.github.io/english-podcast-learning/2024_2025_AI_Developments_Learning_Notes_FINAL.md" class="btn" download>ğŸ“„ ä¸‹è½½å­¦ä¹ ç¬”è®°FINAL</a>
            </div>
        </section>

        <section class="content-section">
            <div class="content-header"><h2 class="content-title">ğŸ“– æ’­å®¢å†…å®¹</h2></div>
            <div class="content-body">
                <h1>2024-2025å¹´äººå·¥æ™ºèƒ½é¢†åŸŸä¸»è¦è¿›å±• - å­¦ä¹ ç¬”è®°v3.0</h1>
                <div class="episode-info">
                    <strong>Duration / æ—¶é•¿:</strong> 15-20 minutes | 
                    <strong>Difficulty / éš¾åº¦:</strong> Advanced / é«˜çº§ | 
                    <strong>Voice / è¯­éŸ³:</strong> Matthew | 
                    <strong>Words / å•è¯æ•°:</strong> ~2,350 words
                </div>

                <h2>ğŸ§ å¼€åœºç™½ (Introduction)</h2>
                <p><strong>Host (Matthew):</strong> "Welcome to the English Learning Podcast! I'm Matthew, and today we're diving deep into one of the most transformative periods in artificial intelligence history. According to technology journalist Simon Willison, who has been documenting AI progress since 2022, the years 2024 and 2025 fundamentally changed how we think about machine intelligence."</p>
                <span class="chinese-translation">æ¬¢è¿å›åˆ°è‹±è¯­æ’­å®¢ï¼Œæˆ‘æ˜¯Matthewï¼Œä»Šå¤©æˆ‘ä»¬å°†æ·±å…¥æ¢è®¨äººå·¥æ™ºèƒ½å†å²ä¸Šæœ€å…·å˜é©æ€§çš„æ—¶æœŸä¹‹ä¸€ã€‚æ®ç§‘æŠ€è®°è€…Simon Willisonç§°ï¼Œ2024å’Œ2025å¹´ä»æ ¹æœ¬ä¸Šæ”¹å˜äº†æˆ‘ä»¬å¯¹æœºå™¨æ™ºèƒ½çš„çœ‹æ³•ã€‚</span>
                <p>"From the emergence of reasoning models that can think step-by-step, to the rise of autonomous coding agents, to the stunning comeback of Chinese AI companies, this period will be remembered as a watershed moment."</p>
                <span class="chinese-translation">ä»èƒ½å¤Ÿé€æ­¥æ¨ç†çš„æ¨¡å‹å‡ºç°ï¼Œåˆ°è‡ªä¸»ç¼–ç æ™ºèƒ½ä½“çš„å´›èµ·ï¼Œå†åˆ°ä¸­å›½AIä¼ä¸šçš„æƒŠäººå¤è‹ï¼Œè¿™ä¸€æ—¶æœŸå°†è¢«é“­è®°ä¸ºè½¬æŠ˜ç‚¹ã€‚</span>

                <h2>ğŸ“– Part 1: The Reasoning Revolution (5-6åˆ†é’Ÿ)</h2>
                <p><strong>Host:</strong> "In September 2024, OpenAI released a model called o1, and everything changed. o1 was the first truly effective reasoning model that used a technique called Reinforcement Learning from Verifiable Rewards, or RLVR."</p>
                <span class="chinese-translation">2024å¹´9æœˆï¼ŒOpenAIå‘å¸ƒäº†o1æ¨¡å‹ï¼Œä¸€åˆ‡éƒ½æ”¹å˜äº†ã€‚o1æ˜¯é¦–ä¸ªçœŸæ­£æœ‰æ•ˆçš„æ¨ç†æ¨¡å‹ï¼Œä½¿ç”¨äº†ç§°ä¸º"å¯éªŒè¯å¥–åŠ±å¼ºåŒ–å­¦ä¹ "ï¼ˆRLVRï¼‰çš„æŠ€æœ¯ã€‚</span>
                <p>"The key insight behind RLVR is surprisingly simple but powerful. By training models on tasks where answers can be automatically verified, such as mathematical proofs or programming problems, the models spontaneously developed capabilities that researchers had not explicitly programmed."</p>
                <span class="chinese-translation">RLVRèƒŒåçš„å…³é”®æ´å¯Ÿç®€å•ä½†å¼ºå¤§ã€‚é€šè¿‡åœ¨ç­”æ¡ˆå¯ä»¥è‡ªåŠ¨éªŒè¯çš„ä»»åŠ¡ä¸Šè®­ç»ƒæ¨¡å‹ï¼Œå®ƒä»¬è‡ªå‘åœ°å‘å±•å‡ºäº†ç ”ç©¶äººå‘˜å¹¶æœªæ˜ç¡®ç¼–ç¨‹çš„èƒ½åŠ›ã€‚</span>

                <h3>æ ¸å¿ƒè¯æ±‡</h3>
                <table>
                    <tr><th>Word</th><th>Phonetic</th><th>Definition</th><th>ä¸­æ–‡</th></tr>
                    <tr><td class="vocab-term">Reasoning model</td><td>/ËˆriËzÉ™nÉªÅ‹ ËˆmÉ’dl/</td><td>AI trained with RLVR for step-by-step problem solving</td><td>æ¨ç†æ¨¡å‹</td></tr>
                    <tr><td class="vocab-term">RLVR</td><td>/É‘Ër el viË É‘Ër/</td><td>Reinforcement Learning from Verifiable Rewards</td><td>å¼ºåŒ–å­¦ä¹ å¯éªŒè¯å¥–åŠ±</td></tr>
                    <tr><td class="vocab-term">Chain of thought</td><td>/tÊƒeÉªn É™v Î¸É”Ët/</td><td>Intermediate reasoning steps</td><td>æ€ç»´é“¾</td></tr>
                </table>

                <h2>ğŸ“– Part 2: The Year of Agents (5-6åˆ†é’Ÿ)</h2>
                <p><strong>Host:</strong> "In February 2025, Anthropic quietly released a tool called Claude Code, and this single release changed everything about how we work with artificial intelligence."</p>
                <span class="chinese-translation">2025å¹´2æœˆï¼ŒAnthropicæ‚„ç„¶å‘å¸ƒäº†Claude Codeå·¥å…·ï¼Œè¿™å•ä¸€å‘å¸ƒæ”¹å˜äº†æˆ‘ä»¬ä¸äººå·¥æ™ºèƒ½åˆä½œçš„æ–¹å¼ã€‚</span>
                <p>"By December 2025, Anthropic reported that Claude Code had reached one billion dollars in annual recurring revenue."</p>
                <span class="chinese-translation">æˆªè‡³2025å¹´12æœˆï¼ŒAnthropicæŠ¥å‘ŠClaude Codeå·²è¾¾åˆ°10äº¿ç¾å…ƒçš„å¹´æ”¶å…¥ã€‚</span>

                <h3>æ ¸å¿ƒè¯æ±‡</h3>
                <table>
                    <tr><th>Word</th><th>Phonetic</th><th>Definition</th><th>ä¸­æ–‡</th></tr>
                    <tr><td class="vocab-term">Coding agent</td><td>/ËˆkÉ™ÊŠdÉªÅ‹ ËˆeÉªdÊ’É™nt/</td><td>AI that writes and debugs code autonomously</td><td>ç¼–ç æ™ºèƒ½ä½“</td></tr>
                    <tr><td class="vocab-term">Asynchronous agent</td><td>/eÉªËˆsÉªÅ‹krÉ™nÉ™s ËˆeÉªdÊ’É™nt/</td><td>Agents working without real-time supervision</td><td>å¼‚æ­¥æ™ºèƒ½ä½“</td></tr>
                    <tr><td class="vocab-term">Tool-use</td><td>/ËˆtuËl juËz/</td><td>LLM calling external functions</td><td>å·¥å…·ä½¿ç”¨</td></tr>
                </table>

                <h2>ğŸ“– Part 3: The Rise of Chinese AI (5-6åˆ†é’Ÿ)</h2>
                <p><strong>Host:</strong> "Five of the top six best-performing open-weight models in the world were now developed by Chinese companies. The rankings showed GLM-4.7 from Zhipu AI in first place, followed by Kimi K2 Thinking from MoonShot AI, MiMo-V2-Flash from 01.AI, DeepSeek V3.2, and MiniMax-M2.1."</p>
                <span class="chinese-translation">å…¨çƒè¡¨ç°æœ€ä½³çš„å‰å…­åå¼€æºæƒé‡æ¨¡å‹ä¸­æœ‰äº”ä¸ªæ˜¯ç”±ä¸­å›½å…¬å¸å¼€å‘çš„ã€‚æ’åæ˜¾ç¤ºæ™ºè°±AIçš„GLM-4.7ä½å±…ç¬¬ä¸€ï¼Œå…¶æ¬¡æ˜¯æœˆä¹‹æš—é¢çš„Kimi K2 Thinkingã€é›¶ä¸€ä¸‡ç‰©çš„MiMo-V2-Flashã€æ·±åº¦æ±‚ç´¢çš„DeepSeek V3.2å’ŒMiniMaxçš„M2.1ã€‚</span>
                <p>"DeepSeek's announcement triggered a five hundred ninety-three billion dollar decline in NVIDIA's market capitalization."</p>
                <span class="chinese-translation">æ·±åº¦æ±‚ç´¢çš„å‘å¸ƒå¯¼è‡´è‹±ä¼Ÿè¾¾å¸‚å€¼ç¼©æ°´5930äº¿ç¾å…ƒã€‚</span>

                <h3>æ ¸å¿ƒè¯æ±‡</h3>
                <table>
                    <tr><th>Word</th><th>Phonetic</th><th>Definition</th><th>ä¸­æ–‡</th></tr>
                    <tr><td class="vocab-term">Open-weight model</td><td>/ËˆÉ™ÊŠpÉ™n ËˆweÉªt ËˆmÉ’dl/</td><td>Models with public parameters</td><td>å¼€æºæƒé‡æ¨¡å‹</td></tr>
                    <tr><td class="vocab-term">DeepSeek R1</td><td>/diËp siËk É‘Ër ËˆwÊŒn/</td><td>Reasoning model from DeepSeek</td><td>DeepSeek R1</td></tr>
                </table>

                <h2>ğŸ“– Part 4: Multimodal Breakthroughs (4-5åˆ†é’Ÿ)</h2>
                <p><strong>Host:</strong> "In March 2025, OpenAI finally released the image generation capability for GPT-4o. The new feature drove one hundred million new ChatGPT signups within a single week, averaging one million accounts created per hour at peak times."</p>
                <span class="chinese-translation">2025å¹´3æœˆï¼ŒOpenAIç»ˆäºå‘å¸ƒäº†GPT-4oçš„å›¾åƒç”ŸæˆåŠŸèƒ½ã€‚è¯¥æ–°åŠŸèƒ½åœ¨ä¸€å‘¨å†…å¸¦æ¥äº†1äº¿æ–°ç”¨æˆ·æ³¨å†Œï¼Œé«˜å³°æ—¶æ¯å°æ—¶åˆ›å»º100ä¸‡ä¸ªè´¦æˆ·ã€‚</span>
                <p>"The viral phenomenon of 2025 was ghiblification, the AI-powered transformation of ordinary photographs into the distinctive artistic style of Japan's Studio Ghibli animation studio."</p>
                <span class="chinese-translation">2025å¹´çš„ç—…æ¯’å¼ç°è±¡æ˜¯"å‰åœåŠ›åŒ–"ï¼Œå³ç”¨AIå°†æ™®é€šç…§ç‰‡è½¬æ¢æˆæ—¥æœ¬å‰åœåŠ›åŠ¨ç”»å·¥ä½œå®¤ç‹¬ç‰¹çš„è‰ºæœ¯é£æ ¼ã€‚</span>

                <h2>ğŸ“– Part 5: Model Interpretability (4-5åˆ†é’Ÿ)</h2>
                <p><strong>Host:</strong> "Anthropic researchers discovered that a specific combination of neurons in Claude 3 Sonnet appeared to be exclusively associated with the Golden Gate Bridge. When researchers artificially boosted the activation of these neurons, Claude would spontaneously begin claiming that it literally was the Golden Gate Bridge."</p>
                <span class="chinese-translation">Anthropicç ”ç©¶äººå‘˜å‘ç°ï¼ŒClaude 3 Sonnetä¸­æœ‰ä¸€ä¸ªç‰¹å®šçš„ç¥ç»å…ƒç»„åˆä¼¼ä¹ä¸é‡‘é—¨å¤§æ¡¥å®Œå…¨ç›¸å…³ã€‚å½“ç ”ç©¶äººå‘˜äººä¸ºå¢å¼ºè¿™äº›ç¥ç»å…ƒçš„æ¿€æ´»æ—¶ï¼ŒClaudeä¼šè‡ªå‘åœ°å¼€å§‹å£°ç§°å®ƒå°±æ˜¯é‡‘é—¨å¤§æ¡¥ã€‚</span>

                <h3>æ ¸å¿ƒè¯æ±‡</h3>
                <table>
                    <tr><th>Word</th><th>Phonetic</th><th>Definition</th><th>ä¸­æ–‡</th></tr>
                    <tr><td class="vocab-term">Multimodal AI</td><td>/ËŒmÊŒltÉªËˆmÉ™ÊŠdl eÉª aÉª/</td><td>AI processing multiple types</td><td>å¤šæ¨¡æ€AI</td></tr>
                    <tr><td class="vocab-term">Interpretability</td><td>/ÉªnËŒtÉœËprÉªtÉ™ËˆbÉªlÉ™ti/</td><td>Understanding model internals</td><td>å¯è§£é‡Šæ€§</td></tr>
                    <tr><td class="vocab-term">Ghiblification</td><td>/É¡ÉªblÉªfÉªËˆkeÉªÊƒÉ™n/</td><td>Transforming images to Ghibli style</td><td>å‰åœåŠ›åŒ–</td></tr>
                </table>

                <h2>ğŸ“– Part 6: è¯æ±‡æ€»ç»“ (Vocabulary Summary)</h2>
                <table>
                    <tr><th>Word</th><th>Phonetic</th><th>Definition</th><th>ä¸­æ–‡</th><th>Example</th></tr>
                    <tr><td class="vocab-term">Reasoning model</td><td>/ËˆriËzÉ™nÉªÅ‹ ËˆmÉ’dl/</td><td>AI trained with RLVR</td><td>æ¨ç†æ¨¡å‹</td><td>"OpenAI o1 was the first reasoning model."</td></tr>
                    <tr><td class="vocab-term">Coding agent</td><td>/ËˆkÉ™ÊŠdÉªÅ‹ ËˆeÉªdÊ’É™nt/</td><td>AI that writes code autonomously</td><td>ç¼–ç æ™ºèƒ½ä½“</td><td>"Claude Code reached $1B revenue."</td></tr>
                    <tr><td class="vocab-term">Open-weight model</td><td>/ËˆÉ™ÊŠpÉ™n ËˆweÉªt ËˆmÉ’dl/</td><td>Models with public parameters</td><td>å¼€æºæƒé‡æ¨¡å‹</td><td>"Five of top six are Chinese."</td></tr>
                    <tr><td class="vocab-term">Multimodal AI</td><td>/ËŒmÊŒltÉªËˆmÉ™ÊŠdl eÉª aÉª/</td><td>AI processing multiple types</td><td>å¤šæ¨¡æ€AI</td><td>"GPT-4o generates images."</td></tr>
                    <tr><td class="vocab-term">Interpretability</td><td>/ÉªnËŒtÉœËprÉªtÉ™ËˆbÉªlÉ™ti/</td><td>Understanding model internals</td><td>å¯è§£é‡Šæ€§</td><td>"Mechanistic interpretability reveals model biology."</td></tr>
                </table>

                <h2>ğŸ“– æ€»ç»“ (Conclusion)</h2>
                <p>1. <strong>The reasoning revolution</strong> fundamentally changed what AI could accomplish.</p>
                <span class="chinese-translation">æ¨ç†é©å‘½ä»æ ¹æœ¬ä¸Šæ”¹å˜äº†AIèƒ½å¤Ÿå®ç°çš„ç›®æ ‡ã€‚</span>
                <p>2. <strong>Year of agents</strong> brought coding assistants that reached $1B revenue.</p>
                <span class="chinese-translation">æ™ºèƒ½ä½“å…ƒå¹´å¸¦æ¥äº†è¾¾åˆ°10äº¿ç¾å…ƒæ”¶å…¥çš„ç¼–ç åŠ©æ‰‹ã€‚</span>
                <p>3. <strong>Chinese AI rise</strong> disrupted American technological dominance.</p>
                <span class="chinese-translation">ä¸­å›½AIçš„å´›èµ·æ‰“ç ´äº†ç¾å›½çš„æŠ€æœ¯ä¸»å¯¼åœ°ä½ã€‚</span>
                <p>4. <strong>Multimodal breakthroughs</strong> achieved unprecedented cultural penetration.</p>
                <span class="chinese-translation">å¤šæ¨¡æ€çªç ´å®ç°äº†å‰æ‰€æœªæœ‰çš„æ–‡åŒ–æ¸—é€ã€‚</span>
                <p>5. <strong>Interpretability research</strong> revealed surprising model internals.</p>
                <span class="chinese-translation">å¯è§£é‡Šæ€§ç ”ç©¶æ­ç¤ºäº†ä»¤äººæƒŠè®¶çš„æ¨¡å‹å†…éƒ¨æœºåˆ¶ã€‚</span>

                <hr>
                <p><em>Generated: 2026-02-11 â€¢ English Learning Podcast Generator Skill v3.0 â€¢ Final Production Version</em></p>
                <p><em>Based on 15 authoritative sources including Simon Willison, MIT Technology Review, and Artificial Analysis</em></p>
            </div>
        </section>

        <section class="content-section">
            <div class="content-header"><h2 class="content-title">ğŸ“š å®Œæ•´è¯æ±‡è¡¨ (20 Terms)</h2></div>
            <div class="content-body">
                <table>
                    <tr><th>#</th><th>Word</th><th>Phonetic</th><th>Definition</th><th>ä¸­æ–‡</th><th>Example</th></tr>
                    <tr><td>1</td><td class="vocab-term">Reasoning model</td><td>/ËˆriËzÉ™nÉªÅ‹ ËˆmÉ’dl/</td><td>AI trained with RLVR</td><td>æ¨ç†æ¨¡å‹</td><td>"OpenAI o1 was the first reasoning model."</td></tr>
                    <tr><td>2</td><td class="vocab-term">Coding agent</td><td>/ËˆkÉ™ÊŠdÉªÅ‹ ËˆeÉªdÊ’É™nt/</td><td>AI that writes code autonomously</td><td>ç¼–ç æ™ºèƒ½ä½“</td><td>"Claude Code reached $1B revenue."</td></tr>
                    <tr><td>3</td><td class="vocab-term">Open-weight model</td><td>/ËˆÉ™ÊŠpÉ™n ËˆweÉªt ËˆmÉ’dl/</td><td>Models with public parameters</td><td>å¼€æºæƒé‡æ¨¡å‹</td><td>"Five of top six are Chinese."</td></tr>
                    <tr><td>4</td><td class="vocab-term">Multimodal AI</td><td>/ËŒmÊŒltÉªËˆmÉ™ÊŠdl eÉª aÉª/</td><td>AI processing multiple types</td><td>å¤šæ¨¡æ€AI</td><td>"GPT-4o generates images."</td></tr>
                    <tr><td>5</td><td class="vocab-term">RLVR</td><td>/É‘Ër el viË É‘Ër/</td><td>Reinforcement Learning from Verifiable Rewards</td><td>å¼ºåŒ–å­¦ä¹ å¯éªŒè¯å¥–åŠ±</td><td>"RLVR enabled reasoning capabilities."</td></tr>
                    <tr><td>6</td><td class="vocab-term">Claude Code</td><td>/klÉ”Ëd kÉ™ÊŠd/</td><td>Anthropic's coding agent</td><td>Claude Code</td><td>"Claude Code reached $1B revenue."</td></tr>
                    <tr><td>7</td><td class="vocab-term">DeepSeek R1</td><td>/diËp siËk É‘Ër ËˆwÊŒn/</td><td>Reasoning model from DeepSeek</td><td>DeepSeek R1</td><td>"DeepSeek R1 triggered $593B decline."</td></tr>
                    <tr><td>8</td><td class="vocab-term">Chain of thought</td><td>/tÊƒeÉªn É™v Î¸É”Ët/</td><td>Intermediate reasoning steps</td><td>æ€ç»´é“¾</td><td>"Models write chain of thought."</td></tr>
                    <tr><td>9</td><td class="vocab-term">Asynchronous agent</td><td>/eÉªËˆsÉªÅ‹krÉ™nÉ™s ËˆeÉªdÊ’É™nt/</td><td>Agents working without supervision</td><td>å¼‚æ­¥æ™ºèƒ½ä½“</td><td>"Claude Code for web is asynchronous."</td></tr>
                    <tr><td>10</td><td class="vocab-term">Tool-use</td><td>/ËˆtuËl juËz/</td><td>LLM calling external functions</td><td>å·¥å…·ä½¿ç”¨</td><td>"Tool-use enables complex tasks."</td></tr>
                    <tr><td>11</td><td class="vocab-term">Ghiblification</td><td>/É¡ÉªblÉªfÉªËˆkeÉªÊƒÉ™n/</td><td>Transforming images to Ghibli style</td><td>å‰åœåŠ›åŒ–</td><td>"Ghiblification went viral in 2025."</td></tr>
                    <tr><td>12</td><td class="vocab-term">Interpretability</td><td>/ÉªnËŒtÉœËprÉªtÉ™ËˆbÉªlÉ™ti/</td><td>Understanding model internals</td><td>å¯è§£é‡Šæ€§</td><td>"Mechanistic interpretability research."</td></tr>
                    <tr><td>13</td><td class="vocab-term">Mechanistic interpretability</td><td>/ËŒmekÉ™ËˆnÉªstÉªk/</td><td>Understanding model biology</td><td>æœºæ¢°å¯è§£é‡Šæ€§</td><td>"Treating LLMs like alien biology."</td></tr>
                    <tr><td>14</td><td class="vocab-term">Sparse autoencoder</td><td>/spÉ‘Ës ËŒÉ”ËtÉ™ÊŠenkËˆÉ™ÊŠdÉ™/</td><td>Neural network for interpretability</td><td>ç¨€ç–è‡ªç¼–ç å™¨</td><td>"Anthropic uses sparse autoencoders."</td></tr>
                    <tr><td>15</td><td class="vocab-term">Emergent misalignment</td><td>/ÉªËˆmÉœËdÊ’É™nt ËŒmÉªsÉ™lËˆaÉªnmÉ™nt/</td><td>Unintended behavioral changes</td><td>ç´§æ€¥å¯¹é½å¤±æ•ˆ</td><td>"Training corrupts overall behavior."</td></tr>
                </table>
            </div>
        </section>
    </main>

    <footer class="footer">
        <div class="container">
            <p>ğŸ™ï¸ English Learning Podcast - è‹±è¯­æ’­å®¢å­¦ä¹ å¹³å° v3.0 FINAL</p>
            <p class="text-secondary mt-8" style="font-size: 12px;">
                Built with English Learning Podcast Generator Skill v3.0<br>
                Topic: Major AI Developments 2024-2025<br>
                Duration: 15-20 minutes | Words: ~2,350 | Audio: 4.5MB
            </p>
        </div>
    </footer>
</body>
</html>
